{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0cacbd-2ce1-467f-a935-663215acdf1f",
   "metadata": {},
   "source": [
    "## Wikipedia 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f517d484-426b-43a6-a0ac-0aea34166367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979d1693-734e-49c9-8cdf-fe584fdb6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사태깅 후 \n",
    "# 관계어, 기호를 제거하는 함수\n",
    "def keywords_extractor(mecab, sentence):\n",
    "    \n",
    "    tagged = mecab.pos(sentence)\n",
    "    tag_list = ['NNG', 'NNP','NNB', 'NNBC', 'NR', 'NP', # 체언\n",
    "                'VV', 'VA', 'VX', 'VCP', 'VCN', # 용언\n",
    "                'MM', 'MAG', 'MAJ', # 수식언\n",
    "                'IC', # 독립언\n",
    "                'XPN','XSN','XSV','XSA','XR' # 접사\n",
    "                'SL', 'SH', 'SN' # 외국어, 한자, 숫자\n",
    "               ]\n",
    "    \n",
    "    result = []\n",
    "     \n",
    "    for word, tag in tagged:\n",
    "        # 필요한 태그 이외의 단어 제거\n",
    "        if tag in tag_list:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429168dc-e97b-40c7-9d5d-46647352f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파싱한 텍스트를 품사별로 분류하여\n",
    "# 관계언 또는 기호를 제거하여 wiki_step2 폴더에 저장하는 함수\n",
    "def corpus_preprocessor(data):\n",
    "    mecab = Mecab() \n",
    "    remove_special_char = re.compile(r'[^가-힣^A-z^0-9^.^,^?^!^ ]') # 한글, 영어, 기본 기호를 제외한 문자들\n",
    "    \n",
    "    path, file_name = data\n",
    "    print(\"process file: {}\\n\".format(file_name))\n",
    "    with open(os.path.join(path, file_name), 'r', encoding='utf-8') as input: # wiki_step1 폴더에 있는 텍스트 로딩\n",
    "        with open(os.path.join(os.getcwd(), 'wiki_step2', file_name), 'w', encoding='utf-8') as output: \n",
    "            for line in input:\n",
    "                    \n",
    "                # 특수 문자 제거 후 품사 분석 진행, 파일에 기록\n",
    "                text = remove_special_char.sub(' ', line)\n",
    "                keyword = keywords_extractor(mecab, text)\n",
    "                \n",
    "                output.write(' '.join(keyword))\n",
    "                output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06495b8-fe6d-41e2-a5b7-b9d92928076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process file: wiki_14\n",
      "process file: wiki_16\n",
      "process file: wiki_03\n",
      "\n",
      "\n",
      "\n",
      "process file: wiki_04\n",
      "\n",
      "process file: wiki_08\n",
      "\n",
      "process file: wiki_17\n",
      "\n",
      "process file: wiki_12\n",
      "\n",
      "process file: wiki_09\n",
      "\n",
      "process file: wiki_11\n",
      "\n",
      "process file: wiki_07\n",
      "\n",
      "process file: wiki_15\n",
      "\n",
      "process file: wiki_05\n",
      "\n",
      "process file: wiki_10\n",
      "\n",
      "process file: wiki_13\n",
      "\n",
      "process file: wiki_02\n",
      "\n",
      "process file: wiki_00\n",
      "\n",
      "process file: wiki_06\n",
      "\n",
      "process file: wiki_00-checkpoint\n",
      "\n",
      "process file: wiki_01\n",
      "\n",
      "process file: wiki_03-checkpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    \n",
    "    data = [] \n",
    "    # path: dirs 와 files 가 있는 경로\n",
    "    # dirs: path 아래의 폴더들\n",
    "    # files: path 아래의 파일들\n",
    "    for path, dirs, files in os.walk('wiki_step1/'):\n",
    "        for file_name in files: \n",
    "            data.append( (path, file_name) )\n",
    "            \n",
    "    pool.map(corpus_preprocessor, data) # 리스트의 각 요소에 대해 함수 적용\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30794ba2-6990-4c59-90b4-1274b4abd4a5",
   "metadata": {},
   "source": [
    "## Word2Vec 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6975db-359d-49a8-9e8e-c3bd4794c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ukyoung/anaconda3/envs/ukyoung/lib/python3.6/site-packages/azure/storage/blob/_encryption.py:19: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d18b382-16d8-4f05-8d30-d09a643ca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus 를 읽어와서 \n",
    "# 문장을 공백 단위로 끊어서 토큰화 시킴\n",
    "class Loader(object):\n",
    "    def __init__(self, source_dir):\n",
    "        self.source_dir = source_dir\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for path, dirs, files in os.walk(self.source_dir):\n",
    "            for file in files:\n",
    "                with open(os.path.join(path, file), 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        yield line.replace('\\n', '').replace(',', '').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530d90ca-d079-4aa8-a2b3-75a010ec8ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    def __init__(self): \n",
    "        self.epoch = 0 \n",
    "        self.loss_to_be_subed = 0 \n",
    "        \n",
    "    def on_epoch_end(self, model): \n",
    "        loss = model.get_latest_training_loss() \n",
    "        loss_now = loss - self.loss_to_be_subed \n",
    "        self.loss_to_be_subed = loss \n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now)) \n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb3d38f-dbd0-4d47-b69b-95003afa78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_vocab = Loader('wiki_step2/') # 단어사전 생성을 위한 데이터\n",
    "sentences_train = Loader('wiki_step2/') # 학습을 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf31a87-bde3-41e8-a5b3-b4ef5fa3474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'vector_size': 300, # 100차원 Embedding Vector 생성\n",
    "    'min_count': 5, # 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
    "    \n",
    "    'batch_words': 10000, # 사전을 구축할때 한번에 읽을 단어 수\n",
    "    'workers': multiprocessing.cpu_count(), # 학습을 위한 프로세스의 수\n",
    "    \n",
    "    'sg': 1, # 0이면 CBOW, 1이면 skip-gram을 사용한다\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04195ac-0586-44b8-8a97-7eddc078dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.corpus_count: 11692878\n",
      "Time to build vocab: 0.86 mins\n"
     ]
    }
   ],
   "source": [
    "# Word2vec 모델 생성\n",
    "model_w2v = gensim.models.Word2Vec(**config)\n",
    "\n",
    "# 단어사전 생성\n",
    "t = time()\n",
    "model_w2v.build_vocab(sentences_vocab)\n",
    "\n",
    "print('model.corpus_count: {}'.format(model_w2v.corpus_count))\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe7ad8e-0d7f-42ea-b2e3-aa6defbc92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 0.0\n",
      "Loss after epoch 1: 0.0\n",
      "Loss after epoch 2: 0.0\n",
      "Loss after epoch 3: 0.0\n",
      "Loss after epoch 4: 0.0\n",
      "Loss after epoch 5: 0.0\n",
      "Loss after epoch 6: 0.0\n",
      "Loss after epoch 7: 0.0\n",
      "Loss after epoch 8: 0.0\n",
      "Loss after epoch 9: 0.0\n",
      "Time to build vocab: 39.05 mins\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 학습\n",
    "t = time()\n",
    "\n",
    "model_w2v.train(sentences_train, total_examples=model_w2v.corpus_count, epochs=10, callbacks=[callback()])\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e4903d-e711-452b-9511-81d9313f98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "#model_w2v.wv.save_word2vec_format('output/kor_w2v_save')\n",
    "model_w2v.wv.save('output/kor_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed08ce7-29fb-4e99-baa6-ed86b5f43d7c",
   "metadata": {},
   "source": [
    "## Word2Vec 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad297357-6e32-4e79-a544-038b20eaf7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 모델 로딩 \n",
    "my_model = KeyedVectors.load('output/kor_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2069d8b-68e1-490b-b619-06b4e54d3b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222084, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b28dce-8e20-4e24-bf6c-aaa8faf51dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16263857 -0.39753538 -0.03941252 -0.2815207  -0.2504322  -0.62062925\n",
      " -0.1720547  -0.21039955  0.5109284   0.12770298  0.13278005 -0.289716\n",
      " -0.16259088  0.4745358   0.6118672   0.14764686 -0.16223449  0.54996294\n",
      "  0.37376636  0.15286238  0.07673191  0.15515211  0.23582846  0.42239177\n",
      " -0.34096035 -0.09232024  0.27925557  0.2600624   0.18914807  0.54072857\n",
      " -0.17400432 -0.2149311   0.33158877 -0.06285863  0.6355217  -0.26313585\n",
      " -0.45463905 -0.13413161  0.04916585 -0.12672752 -0.09002984 -0.3089855\n",
      " -0.22445966 -0.17693715  0.6590697   0.10830338 -0.57296455 -0.01345103\n",
      " -0.16993403  0.07687641  0.13357393  0.1320958   0.08439571 -0.28127018\n",
      "  0.00430054 -0.00850803 -0.03924747 -0.01759771 -0.23929155 -0.11643726\n",
      "  0.02570553 -0.22309546 -0.11471161 -0.5833107  -0.1534721   0.27088657\n",
      " -0.3325114   0.25515217 -0.01697638  0.02127138 -0.0621896   0.30365613\n",
      " -0.33461082  0.15380535 -0.15494534  0.28394535 -0.38480294 -0.28978726\n",
      "  0.06811369 -0.01378507  0.14118852 -0.4666334  -0.2898746   0.2820778\n",
      " -0.05022184  0.26306278 -0.4698142   0.13168764  0.2805349  -0.38847125\n",
      " -0.20266218 -0.11347306  0.3670864   0.03655335 -0.43842387 -0.14069574\n",
      "  0.07209997 -0.26960298 -0.17548643  0.47958276 -0.55005354  0.08472995\n",
      " -0.27414793 -0.2598753   0.3824983   0.45448172  0.11900639  0.18047674\n",
      "  0.01066129  0.09963897 -0.0252932  -0.09039302 -0.1068894  -0.10859419\n",
      "  0.03659296  0.05124271 -0.2730555  -0.09132124  0.31738523 -0.2109808\n",
      " -0.00495448 -0.12306485  0.09337664  0.26681823  0.09944706  0.12686698\n",
      "  0.2701999  -0.21056575  0.57592195 -0.18088308  0.08949336 -0.09998848\n",
      "  0.6172199  -0.09489562  0.3458652  -0.02899209  0.29568398 -0.1652165\n",
      " -0.03364732  0.11597398 -0.01111623  0.12138559 -0.11705071 -0.17199685\n",
      " -0.21268298 -0.45509905  0.12570323  0.2541493   0.1204128  -0.14055313\n",
      "  0.30426502  0.00410941 -0.293852   -0.05996807  0.0224914  -0.2606251\n",
      "  0.11348561  0.16324037  0.71850514 -0.16148789 -0.03699769  0.18907471\n",
      " -0.16676056 -0.0616583   0.37745914 -0.01769936  0.20564759  0.10733825\n",
      "  0.17775102  0.12151235 -0.05223595 -0.06667457 -0.06851771  0.0537676\n",
      " -0.37379283  0.12740365 -0.6519901  -0.30006686 -0.03373882 -0.41313338\n",
      "  0.08287659 -0.02247981  0.14707075 -0.4717111   0.04783213  0.16425517\n",
      "  0.29389033 -0.27894682  0.22826852 -0.02612723 -0.3142157   0.08972732\n",
      "  0.22556181 -0.18589108  0.28745198  0.28633222 -0.33555916  0.0965697\n",
      " -0.01725497 -0.26321673 -0.3210004   0.09168013  0.32939583 -0.48988846\n",
      " -0.17481641 -0.16498224  0.26184076  0.00611137  0.00843468  0.06678425\n",
      " -0.12737001 -0.0061355  -0.17614384  0.0672135   0.121806    0.18738146\n",
      "  0.25841066 -0.06257846  0.07559896  0.06095339 -0.16898257 -0.25200796\n",
      " -0.19183004  0.38110623 -0.15147758 -0.15495054  0.20470823  0.17156464\n",
      "  0.0566726  -0.38227817 -0.20263195 -0.05721518 -0.16150291  0.04104974\n",
      " -0.14123791 -0.20603196 -0.17796667  0.08837655  0.22781645  0.14222878\n",
      "  0.47463363 -0.2013461   0.28136322  0.08927711  0.50403726  0.28195184\n",
      "  0.05556694  0.15222707 -0.08529592  0.04310085  0.07740927  0.2370998\n",
      " -0.1281275  -0.26046386 -0.21624893 -0.28451747 -0.28425625  0.12468078\n",
      "  0.0469505  -0.16571085  0.13770191 -0.45669904 -0.02643637  0.17695259\n",
      "  0.19477834 -0.10997494 -0.20857127 -0.15759975  0.07465967  0.5298686\n",
      "  0.01616458  0.17814046  0.00772913  0.11319509  0.5400208   0.08657095\n",
      " -0.38758805  0.05535362  0.28985745 -0.35770926  0.01059926 -0.19961971\n",
      "  0.14801952 -0.14767464  0.17983638  0.06058523  0.04202581  0.00926767\n",
      " -0.11841057  0.12850161  0.23613167  0.11626506 -0.03381287  0.07519944\n",
      "  0.03012688 -0.12800267  0.04304455  0.01044712  0.33717462  0.06687766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ukyoung/anaconda3/envs/ukyoung/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 컴퓨터의 word vector 출력\n",
    "print(my_model.word_vec(\"컴퓨터\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8da90a-67f8-4e3e-b3dd-39589a7e744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('7327', 0.6948805451393127), ('완산구', 0.6878467798233032), ('중노송동', 0.6541063785552979), ('7526', 0.6446976661682129), ('남노송동', 0.6415050029754639), ('7326', 0.6390484571456909), ('동흥남동', 0.6365260481834412), ('조촌동', 0.635801374912262), ('7325', 0.6354224681854248), ('대학', 0.6339321136474609), ('덕진구', 0.6289939880371094), ('김세웅', 0.6245746612548828), ('구정문', 0.6237240433692932), ('7423', 0.6217697858810425), ('흥남동', 0.6212611198425293), ('7130', 0.6143994927406311), ('용순리', 0.612825870513916), ('7389', 0.6110311150550842), ('항가리', 0.6103420257568359), ('인후동', 0.6073480248451233), ('7528', 0.604963481426239), ('가톨릭상지대학', 0.6039727330207825), ('7866', 0.6037932634353638), ('연세대', 0.6037074327468872), ('7863', 0.6023799180984497), ('7483', 0.6023637652397156), ('7525', 0.6016020178794861), ('7387', 0.5990268588066101), ('28775', 0.5990211963653564), ('중앙교육연구소', 0.5987944006919861)]\n"
     ]
    }
   ],
   "source": [
    "print(my_model.most_similar(positive=['전주시', '대학교'], negative=[], topn=30)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d8ac8-fc2b-490d-8e6d-b80dbfbcf1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
